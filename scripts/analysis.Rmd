---
title: "Weighted Analyses"
author: "steppe"
date: "2022-12-12"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Load Libraries}
library(tidyverse)
library(spsurvey)
```


```{r Load and subset data to field office, warning = F}
pr <- '../data/raw'
f <- list.files(pr, recursive = T)

UFO_borders <- st_read(file.path(pr, f[grep('*admu.*shp$', f)]), quiet = T) %>% 
  filter(str_detect(ADMU_NAME, 'UNCOMPAHGRE')) %>% 
  st_transform(4269) %>% 
  select(geometry)

summaries <- read.csv(file.path(pr, f[grep('*Hub*', f)])) %>% 
  filter(State == 'CO') %>%  # reduce to your state of interest 
  select(-X, -Y, -State:-EcolSiteName, -DateVisited, -Purpose:-DBKey, -PrimaryKey, 
         -starts_with("RH_"), -starts_with('Sagebrush'), -starts_with('Spp_')) %>% 
  st_as_sf(coords = c(x = 'Longitude_NAD83', y = 'Latitude_NAD83'), crs = 4269, remove = F) %>%  # now make spatial
  st_intersection(UFO_borders, .) %>% 
  select_if(~sum(!is.na(.)) > 0)

rm(UFO_borders)
```


```{r Filter TerraDat to grab only base AIM plots and add post strat names}

baseplots <- st_read(file.path(pr, f[grep('*Design.*shp$', f)]), quiet = T) %>% 
  filter(!str_detect(PANEL, 'Over')) %>% 
  pull(PLOTID)

summaries <- summaries %>% 
  mutate(PlotID = str_replace(PlotID, 'Other', 'OT'),
         PlotID = str_replace(PlotID, 'Rip', 'RI')) %>% 
  filter(PlotID %in% baseplots)

restrat <- st_read(file.path(pr, f[grep('reclassified.*shp$', f)]), quiet = T) %>% 
  st_drop_geometry() %>% 
  select(-Plot)

summaries <- left_join(summaries, restrat, by = 'PlotKey')
  
rm(f, pr, baseplots, restrat)
```


```{r Filter dataset for only variables which have variation}

summary_cols_not_applicable <- summaries %>% # find columns, where fractional cover
  select(where(~ is.numeric(.x) && sum(.x, na.rm = T) == 0)) %>% # in all rows
  colnames() # is equal to 0, these are func. grps. not present in the area of analysis

NA_per_col <- summaries %>% # we can identify columns which have MANY NA values in them
  st_drop_geometry() %>% # perhaps if > 10% of your values per variables are NA
  summarise(across(.cols = everything(),  ~ (sum(is.na(.))))/nrow(.) * 100) %>% 
  select(where(~ .x >= 10)) # you want to take a look at them - Ours are not too bad.

Variation <- summaries %>% # IDENTIFY COLUMNS with little to no variation in the 
  st_drop_geometry() %>% # measured variables, if we see var == 0, all measurements
  select(where(~ is.numeric(.x))) %>%  # were the same but not caught by 'summary cols not applicable'
  summarise(across(.cols = everything(), ~ # we do not have this problem which may
                     var(scales::rescale(., to = c(0,1), na.rm = T), na.rm = T))) %>% 
  t() %>% # arise if we always have the same response of an encoded categorical variable
  data.frame() %>% # we can still see which of the variables have littler variance
  rownames_to_column('Variable') %>% rename(Variance = '.') %>% # here
  filter(!Variable %in% c('OBJECTID', 'Latitude_NAD83', 'Longitude_NAD83', 'YearEstablished'))

hist(Variation$Variance) # the values far left are seldom recorded, e.g. we got rid of vagrant lichen years ago!

summaries1 <- summaries %>% 
  st_drop_geometry() %>% 
  filter(is.na(SoilStability_All)) %>% 
  mutate(across(starts_with('SoilStability'), ~ 999))
summaries <- summaries %>% 
  filter(!PlotID %in% summaries1$PlotID) %>% 
  bind_rows(., summaries1)

summaries <- summaries %>% 
  select(-any_of(summary_cols_not_applicable)) %>% 
  mutate(DateEstablished = as.Date(DateEstablished), # convert to date format
         YearEstablished = as.numeric(format(DateEstablished,'%Y'), .)
         )

rm(summary_cols_not_applicable, NA_per_col, Variation, summaries1)
```


```{r Datasets which may be evaluated for Percent acreage}


# maybe write function that continuously tests the number of plots per group which
# have > 2 records > 0. This should allow us to calculate these values for each stratum
# otherwise some of the values that we will miss are too important to be left behind !
# many of the noxious values would be missed if we did this. !


#' A wrapper function for using spsurveys cont_analysis Prt statistic
#' 
#' @Description For use with strata and/or subpops which may have groups with 
#' several 0 values which do not allow spsurvey to calculate percent standards.
#' This function wraps around cont_analysis and will truncate those groups from 
#' analysis, and append rows indicating that this operation was performed.
#' 
#' @param x a dataframe or sf tibble 
#' @param grp_var1 one level of grouping variables - required
#' @param grp_var2 another level of grouping variable - not required and defaults to none
#' @param variables the variables which you are going to compute - see example. 
#' @param ... additional arguments passed onto cont analysis e.g. pctval, cols holding coords
#' 
#' 
prcnt_meeting <- function(x, grp_var1, variables, ...){
  
  # determine how many observations with values > 0 exist, if < 2, this value cannot
  # be interpolated from the continual analysis function below. 

  grps2keep <- x %>% 
    group_by(!!sym(grp_var1)) %>%
    drop_na(!!sym(variables)) %>% 
    filter(!!sym(variables) > 0) %>%  
    mutate(Records = n()) %>% 
    filter(Records > 2) %>% 
    distinct(!!sym(grp_var1)) %>% 
    pull(!!sym(grp_var1)) 
  
  if(length(grps2keep) > 0) {
   x <- filter(x, !!sym(grp_var1) %in% grps2keep)
   } else{x}
  
  if(nrow(x) > 1){
    return_vals <- cont_analysis(dframe = x, statistics = 'Pct', vars = variables,
                               subpops = as.character(substitute(grp_var1)), ...)
    return_vals <- return_vals[['Pct']]
  } else {'waterboy'}
  
  return(grps2keep)
  
}


sum2 <- drop_na(sum2, Veg_type)

out <- prcnt_meeting(x = sum2, grp_var1 = 'Veg_type', variables = 'AH_NoxPerenForbCover', #, 'Hgt_NonNoxPerenGrass_Avg'), 
                     pctval = c(70, 80), conf = 80 )
out

errorprnt()


sum2 <- sum1 %>% select(Veg_type, AH_NoxPerenForbCover)






 grps2remove <- sum1 %>% 
    group_by(Veg_type) %>% 
    drop_na(AH_NoxPerenForbCover) %>% 
    filter(AH_NoxPerenForbCover > 0) %>%  
    mutate(Records = n()) %>% 
    filter(Records < 2) %>% 
    distinct(Veg_type) %>% 
    pull(Veg_type) 


```


```{r Add Post Strat Values to figures}


sum1 <- summaries %>% 
  separate(PlotID, into = 'Stratum', sep = '-', remove = F, extra = 'drop') %>% 
  mutate(Stratum = factor(Stratum)) %>% 
  st_transform(26912) %>% 
  mutate(xcoord = unlist(map(.$geometry,1)),
         ycoord = unlist(map(.$geometry,2))) %>% 
  filter(PlotID != 'GR-021')

v <- data.frame(weight = wakefield::probs(length(unique(sum1$Stratum))),
           Stratum = unique(sum1$Stratum))
sum1 <- left_join(sum1, v, by = 'Stratum')

noxious <- sum1 %>% 
  select(Veg_type, contains("_Nox"), weight)

nox_cols <- noxious %>% 
  st_drop_geometry() %>% 
  select(-Veg_type) %>% 
  colnames()

noxious_vals <- cont_analysis(dframe = noxious, subpops = 'Veg_type', vars = nox_cols, statistics = 'Mean',
              xcoord = 'xcoord', ycoord = 'ycoord', conf = 80, pctval = c(70, 80))


v <- cont_analysis(dframe = sum1, subpops = 'Veg_type', vars = nox_cols[1], statistics = 'Pct',
              xcoord = 'xcoord', ycoord = 'ycoord', conf = 80, pctval = c(70, 80))

pctv <- v[['Pct']] # XX Percent of the land which is achieving a standard. 
meanv <- v[['Mean']] # easy peasy is the mean, and how certain we are that our calculation of it is true

v1 <- c('GapCover_25_50', 'GapCover_51_100')

cols2calc <- sum1 %>% 
  select(where(is.numeric)) %>% 
  select(BareSoilCover:Hgt_Sagebrush_Live_Avg) %>% 
  st_drop_geometry() %>% 
  colnames()

strt <- Sys.time()
v2 <- cont_analysis(dframe = sum1, subpops = 'Stratum', vars = cols2calc, statistics = 'Mean',
              xcoord = 'xcoord', ycoord = 'ycoord', conf = 80)
v2 <- v2['Mean'] %>% bind_rows()
Sys.time() - strt

strt <- Sys.time()
v3 <- cont_analysis(dframe = sum1, subpops = 'Stratum', vars = cols2calc[7:25], statistics = 'Pct',
              xcoord = 'xcoord', ycoord = 'ycoord', conf = 80, pctval = c(70)) # 80% for WSA and ACEC's otherwise 70!
v3 <- v3['Mean'] %>% bind_rows()
Sys.time() - strt

```

