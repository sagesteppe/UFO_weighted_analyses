---
title: "Weighted Analyses"
author: "steppe"
date: "2022-12-12"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Load Libraries}
library(tidyverse)
library(spsurvey)

source('functions.R')
```


```{r Load and subset data to field office, warning = F}
pr <- '../data/raw'
f <- list.files(pr, recursive = T)

UFO_borders <- st_read(file.path(pr, f[grep('*admu.*shp$', f)]), quiet = T) %>% 
  filter(str_detect(ADMU_NAME, 'UNCOMPAHGRE')) %>% 
  st_transform(4269) %>% 
  select(geometry)

summaries <- read.csv(file.path(pr, f[grep('*Hub*', f)])) %>% 
  filter(State == 'CO') %>%  # reduce to your state of interest 
  select(-X, -Y, -State:-EcolSiteName, -DateVisited, -Purpose:-DBKey, -PrimaryKey, 
         -starts_with("RH_"), -starts_with('Sagebrush'), -starts_with('Spp_')) %>% 
  st_as_sf(coords = c(x = 'Longitude_NAD83', y = 'Latitude_NAD83'), crs = 4269, remove = F) %>%  # now make spatial
  st_intersection(UFO_borders, .) %>% 
  select_if(~sum(!is.na(.)) > 0)

rm(UFO_borders)
```


```{r Filter TerraDat to grab only base AIM plots and add post strat names}

baseplots <- st_read(file.path(pr, f[grep('*Design.*shp$', f)]), quiet = T) %>% 
  filter(!str_detect(PANEL, 'Over')) %>% 
  pull(PLOTID)

summaries <- summaries %>% 
  mutate(PlotID = str_replace(PlotID, 'Other', 'OT'),
         PlotID = str_replace(PlotID, 'Rip', 'RI')) %>% 
  filter(PlotID %in% baseplots)

restrat <- st_read(file.path(pr, f[grep('reclassified.*shp$', f)]), quiet = T) %>% 
  st_drop_geometry() %>% 
  select(-Plot)

summaries <- left_join(summaries, restrat, by = 'PlotKey')
  
rm(f, pr, baseplots, restrat)
```


```{r Filter dataset for only variables which have variation}

summary_cols_not_applicable <- summaries %>% # find columns, where fractional cover
  select(where(~ is.numeric(.x) && sum(.x, na.rm = T) == 0)) %>% # in all rows
  colnames() # is equal to 0, these are func. grps. not present in the area of analysis

NA_per_col <- summaries %>% # we can identify columns which have MANY NA values in them
  st_drop_geometry() %>% # perhaps if > 10% of your values per variables are NA
  summarise(across(.cols = everything(),  ~ (sum(is.na(.))))/nrow(.) * 100) %>% 
  select(where(~ .x >= 10)) # you want to take a look at them - Ours are not too bad.

zero_per_col <- summaries %>% # we can identify columns which have MANY 0 values
  st_drop_geometry() %>% # perhaps > 75 percent 0 is too many zereos!
  summarise(across(.cols = everything(), ~ sum(.x == 0))/nrow(.) * 100)  %>%
  mutate(across(.cols = everything(), ~ if_else(is.na(.x), 0, .x))) %>% 
  select(where(~ .x >= 75))

Variation <- summaries %>% # IDENTIFY COLUMNS with little to no variation in the 
  st_drop_geometry() %>% # measured variables, if we see var == 0, all measurements
  select(where(~ is.numeric(.x))) %>%  # were the same but not caught by 'summary cols not applicable'
  summarise(across(.cols = everything(), ~ # we do not have this problem which may
                     var(scales::rescale(., to = c(0,1), na.rm = T), na.rm = T))) %>% 
  t() %>% # arise if we always have the same response of an encoded categorical variable
  data.frame() %>% # we can still see which of the variables have littler variance
  rownames_to_column('Variable') %>% rename(Variance = '.') %>% # here
  filter(!Variable %in% c('OBJECTID', 'Latitude_NAD83', 'Longitude_NAD83', 'YearEstablished'))

hist(Variation$Variance) # the values far left are seldom recorded, e.g. we got rid of vagrant lichen years ago!

summaries1 <- summaries %>% 
  st_drop_geometry() %>% 
  filter(is.na(SoilStability_All)) %>% 
  mutate(across(starts_with('SoilStability'), ~ 999))
summaries <- summaries %>% 
  filter(!PlotID %in% summaries1$PlotID) %>% 
  bind_rows(., summaries1)

summaries <- summaries %>% 
  select(-any_of(summary_cols_not_applicable)) %>% 
  mutate(DateEstablished = as.Date(DateEstablished), # convert to date format
         YearEstablished = as.numeric(format(DateEstablished,'%Y'), .)
         )

rm(summary_cols_not_applicable, NA_per_col, Variation, summaries1)
```


```{r Datasets which may be evaluated for Percent acreage}


sum1 <- summaries %>% 
  separate(PlotID, into = 'Stratum', sep = '-', remove = F, extra = 'drop') %>% 
  mutate(Stratum = factor(Stratum)) %>% 
  st_transform(26912) %>% 
  mutate(xcoord = unlist(map(.$geometry,1)),
         ycoord = unlist(map(.$geometry,2))) %>% 
  filter(PlotID != 'GR-021')

v <- data.frame(weight = wakefield::probs(length(unique(sum1$Stratum))),
           Stratum = unique(sum1$Stratum))
sum1 <- left_join(sum1, v, by = 'Stratum')

contVars2Calc <- colnames(sum1)
contVars2Calc <- contVars2Calc[!contVars2Calc %in% c('geometry', 'ycoord', 'xcoord', 'Veg_type', 'YearEstablished',
                          'Latitude_NAD83', 'Longitude_NAD83', 'GlobalID',
                  'weight', 'OBJECTID', "PlotKey", 'PlotID','Stratum', 'DateEstablished')]

contVarsInter <- vector(mode = 'list', length = length(contVars2Calc))
for (i in seq(contVars2Calc)){
  contVarsInter[[i]] <- prcnt_meeting(x = sum1, grp_var1 = 'Veg_type',  variables = contVars2Calc[i],  
                     pctval = c(70, 80), conf = 80 )
}

contVarsInter <- bind_rows(contVarsInter)

rm(i, contVars2Calc)
```


```{r Add Post Strat Values to figures}



noxious_vals <- cont_analysis(dframe = noxious, subpops = 'Veg_type', vars = nox_cols, statistics = 'Mean',
              xcoord = 'xcoord', ycoord = 'ycoord', conf = 80, pctval = c(70, 80))


v <- cont_analysis(dframe = sum1, subpops = 'Veg_type', vars = nox_cols[1], statistics = 'Pct',
              xcoord = 'xcoord', ycoord = 'ycoord', conf = 80, pctval = c(70, 80))

pctv <- v[['Pct']] # XX Percent of the land which is achieving a standard. 
meanv <- v[['Mean']] # easy peasy is the mean, and how certain we are that our calculation of it is true

v1 <- c('GapCover_25_50', 'GapCover_51_100')

cols2calc <- sum1 %>% 
  select(where(is.numeric)) %>% 
  select(BareSoilCover:Hgt_Sagebrush_Live_Avg) %>% 
  st_drop_geometry() %>% 
  colnames()

strt <- Sys.time()
v2 <- cont_analysis(dframe = sum1, subpops = 'Stratum', vars = cols2calc, statistics = 'Mean',
              xcoord = 'xcoord', ycoord = 'ycoord', conf = 80)
v2 <- v2['Mean'] %>% bind_rows()
Sys.time() - strt

strt <- Sys.time()
v3 <- cont_analysis(dframe = sum1, subpops = 'Stratum', vars = cols2calc[7:25], statistics = 'Pct',
              xcoord = 'xcoord', ycoord = 'ycoord', conf = 80, pctval = c(70)) # 80% for WSA and ACEC's otherwise 70!
v3 <- v3['Mean'] %>% bind_rows()
Sys.time() - strt

```

